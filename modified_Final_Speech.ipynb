{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ANACONDA3\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "#Install all the Reqiuired Libraries and Packages \n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc , logfbank\n",
    "import librosa as lr\n",
    "import os, glob, pickle\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import noisereduce as nr\n",
    "from glob import glob\n",
    "import librosa\n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the required RAVDESS DataSet with length of 1439 Audio Files \n",
    "os.listdir(path='.\\speech-emotion-recognition-ravdess-data')\n",
    "def getListOfFiles(dirName):\n",
    "    listOfFile=os.listdir(dirName)\n",
    "    allFiles=list()\n",
    "    for entry in listOfFile:\n",
    "        fullPath=os.path.join(dirName, entry)\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles=allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "    return allFiles\n",
    "\n",
    "dirName = './speech-emotion-recognition-ravdess-data'\n",
    "listOfFiles = getListOfFiles(dirName)\n",
    "len(listOfFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talking by the door\n",
      "kids talking by the door\n",
      "dog sitting by the door\n",
      "talk to Siri why the door\n",
      "error\n",
      "talking by the door\n",
      "the door\n",
      "dog sitting by the door\n",
      "change your talking by the door\n",
      "talking by the door\n",
      "dog sitting by the door\n",
      "sitting by the door\n",
      "talking by the door\n",
      "talking by the door\n",
      "dog sitting by the door\n",
      "dogs are sitting by the door\n",
      "talking by the door\n",
      "error\n",
      "sitting by the door\n",
      "dogs are sitting by the door\n",
      "kids talking by the door\n",
      "khesa talking by the door\n",
      "sitting by the door\n",
      "error\n",
      "kids talking by the door\n",
      "talking by the door\n",
      "dogs are sitting by the door\n",
      "sitting by the door\n",
      "kids are talking by the door\n",
      "talking by the door\n",
      "sitting by the door\n",
      "sitting by the door\n",
      "talking by the door\n",
      "talking by the door\n",
      "dogs are sitting by the door\n",
      "spelling for the tour\n",
      "talking by the door\n",
      "kids talking by the door\n",
      "toxicity by the door\n",
      "dogs sitting by the door\n",
      "f****** by the door\n",
      "talking to the door\n",
      "Rockstar ceiling by the door\n",
      "ceiling\n",
      "the door\n",
      "error\n",
      "sitting by the door\n",
      "error\n",
      "kids talking by the door\n",
      "talking by the tomorrow\n",
      "sitting by the door\n",
      "exit the door\n",
      "talking by the door\n",
      "talking by the door\n",
      "dogs sitting by the door\n",
      "error\n",
      "talking by the door\n",
      "talking by the door\n",
      "sitting by the door\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "#Use the Speech-Recognition API to get the Raw Text from Audio Files, Though Speech Recognition\n",
    "#is less strong for large chunk of files , so used Error Handling , where when it is not be able to \n",
    "#produce the text of a particular Audio File it prints the statement 'error'.Just for understanding Audio\n",
    "import speech_recognition as sr\n",
    "r=sr.Recognizer()\n",
    "for file in range(0 , len(listOfFiles) , 1):\n",
    "    with sr.AudioFile(listOfFiles[file]) as source:\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(text)\n",
    "        except:\n",
    "            print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the Basic Graphs for understanding of Audio Files :\n",
    "for file in range(0 , len(listOfFiles) , 1):\n",
    "    audio , sfreq = lr.load(listOfFiles[file])\n",
    "    time = np.arange(0 , len(audio)) / sfreq\n",
    "    \n",
    "    fig ,ax = plt.subplots()\n",
    "    ax.plot(time , audio)\n",
    "    ax.set(xlabel = 'Time (s)' , ylabel = 'Sound Amplitude')\n",
    "    plt.show()\n",
    "    \n",
    "#PLOT THE SEPCTOGRAM\n",
    "for file in range(0 , len(listOfFiles) , 1):\n",
    "    samples,sample_rate =librosa.load(listOfFiles[file])#      sample_rate , samples = wavfile.read(listOfFiles[file])\n",
    "    frequencies , times, spectrogram = signal.spectrogram(samples, sample_rate) \n",
    "    plt.pcolormesh(times, frequencies, spectrogram)\n",
    "    plt.imshow(spectrogram)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Step is In-Depth Visualisation of Audio Fiels and its certain features to plot for.\n",
    "#They are the Plotting Functions to be called later. \n",
    "def plot_signals(signals):\n",
    "    fig , axes = plt.subplots(nrows=2, ncols=5,sharex =False , sharey=True, figsize=(20,5))\n",
    "    fig.suptitle('Time Series' , size=16)\n",
    "    i=0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(signals.keys())[i])\n",
    "            axes[x,y].plot(list(signals.values())[i])\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i +=1\n",
    "\n",
    "def plot_fft(fft):\n",
    "    fig , axes = plt.subplots(nrows=2, ncols=5,sharex =False , sharey=True, figsize=(20,5))\n",
    "    fig.suptitle('Fourier Transform' , size=16)\n",
    "    i=0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            data = list(fft.values())[i]\n",
    "            Y,freq = data[0] , data[1]\n",
    "            axes[x,y].set_title(list(fft.keys())[i])\n",
    "            axes[x,y].plot(freq , Y)\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i +=1\n",
    "    \n",
    "def plot_fbank(fbank):\n",
    "    fig , axes = plt.subplots(nrows=2, ncols=5,sharex =False , sharey=True, figsize=(20,5))\n",
    "    fig.suptitle('Filter Bank Coefficients' , size=16)\n",
    "    i=0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(fbank.keys())[i])\n",
    "            axes[x,y].imshow(list(fbank.values())[i],cmap='hot', interpolation = 'nearest')\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i +=1\n",
    "            \n",
    "def plot_mfccs(mfccs):\n",
    "    fig , axes = plt.subplots(nrows=2, ncols=5,sharex =False , sharey=True, figsize=(20,5))\n",
    "    fig.suptitle('Mel Frequency Capstrum  Coefficients' , size=16)\n",
    "    i=0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(mfccs.keys())[i])\n",
    "            axes[x,y].imshow(list(mfccs.values())[i],\n",
    "                             cmap='hot', interpolation = 'nearest')\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i +=1\n",
    "\n",
    "def calc_fft(y,rate):\n",
    "    n = len(y)\n",
    "    freq = np.fft.rfftfreq(n , d= 1/rate)\n",
    "    Y= abs(np.fft.rfft(y)/n)\n",
    "    return(Y,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here The Data Set is loaded and plots are Visualised by Calling the Plotting Functions . \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "import numpy as np\n",
    "for file in range(0 , len(listOfFiles) , 1):\n",
    "    data,rate =librosa.load(listOfFiles[file])      #     rate, data = wav.read(listOfFiles[file])   \n",
    "    fft_out = fft(data)\n",
    "    %matplotlib inline\n",
    "    plt.plot(data, np.abs(fft_out))\n",
    "    plt.show()\n",
    "    \n",
    "signals={}\n",
    "fft={}\n",
    "fbank={}\n",
    "mfccs={}\n",
    "# load data\n",
    "for file in range(0 , len(listOfFiles) , 1):\n",
    "#     rate, data = wavfile.read(listOfFiles[file])\n",
    "     signal,rate =librosa.load(listOfFiles[file] , sr=44100)\n",
    "     mask = envelope(signal , rate , 0.0005)\n",
    "     signals[file] = signal\n",
    "     fft[file] = calc_fft(signal , rate)\n",
    "    \n",
    "     bank = logfbank(signal[:rate] , rate , nfilt = 26, nfft = 1103).T\n",
    "     fbank[file] = bank\n",
    "     mel = mfcc(signal[:rate] , rate , numcep =13 , nfilt = 26 , nfft=1103).T\n",
    "     mfccs[file]=mel\n",
    "\n",
    "plot_signals(signals)\n",
    "plt.show()\n",
    "\n",
    "plot_fft(fft)\n",
    "plt.show()\n",
    "\n",
    "plot_fbank(fbank)\n",
    "plt.show()\n",
    "\n",
    "plot_mfccs(mfccs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Cleaning Step is Performed where:\n",
    "#DOWN SAMPLING OF AUDIO FILES IS DONE  AND PUT MASK OVER IT AND DIRECT INTO CLEAN FOLDER\n",
    "#MASK IS TO REMOVE UNNECESSARY EMPTY VOIVES AROUND THE MAIN AUDIO VOICE \n",
    "def envelope(y , rate, threshold):\n",
    "    mask=[]\n",
    "    y=pd.Series(y).apply(np.abs)\n",
    "    y_mean = y.rolling(window=int(rate/10) ,  min_periods=1 , center = True).mean()\n",
    "    for mean in y_mean:\n",
    "        if mean>threshold:\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:11<00:00,  5.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#The clean Audio Files are redirected to Clean Audio Folder Directory \n",
    "import glob,pickle\n",
    "# for file in tqdm(glob.glob(r'C:\\Users\\Sakshi jain\\speech-emotion-recognition-ravdess-data\\\\**\\\\*.wav')):\n",
    "for file in tqdm(glob.glob(r'C:\\Users\\PRIYANSHU PANDEY\\Desktop\\Stuti\\Ravdess small sample datase\\speech-emotion-recognition-ravdess-data\\\\**\\\\*.wav')):\n",
    "    file_name = os.path.basename(file)\n",
    "    signal , rate = librosa.load(file, sr=16000)\n",
    "    mask = envelope(signal,rate, 0.0005)\n",
    "    wavfile.write(filename= r'C:\\Users\\PRIYANSHU PANDEY\\Desktop\\Stuti\\Ravdess small sample datase\\clean_speech\\\\'+str(file_name), rate=rate,data=signal[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#All the Required Packages and Libraies are installed.\n",
    "import soundfile\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D, Flatten, LSTM\n",
    "from keras.layers import Dropout,Dense,TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction of Audio Files Function \n",
    "#Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotions in the RAVDESS dataset to be classified Audio Files based on . \n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "#These are the emotions User wants to observe more :\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and extract features for each sound file\n",
    "from glob import glob\n",
    "import os\n",
    "import glob\n",
    "def load_data(test_size=0.33):\n",
    "    x,y=[],[]\n",
    "    answer = 0\n",
    "    for file in glob.glob(r'C:\\Users\\PRIYANSHU PANDEY\\Desktop\\Stuti\\Ravdess small sample datase\\clean_speech\\\\*.wav'):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            answer += 1\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append([emotion,file_name])\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 180) (8, 180) (24, 2) (8, 2)\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "x_train,x_test,y_trai,y_tes=load_data(test_size=0.25)\n",
    "print(np.shape(x_train),np.shape(x_test), np.shape(y_trai),np.shape(y_tes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,) (8,)\n",
      "03-01-02-02-01-01-01.wav\n",
      "03-01-06-01-02-02-01.wav\n",
      "03-01-03-01-01-02-01.wav\n",
      "03-01-03-02-01-02-01.wav\n",
      "03-01-03-01-02-02-01.wav\n",
      "03-01-02-02-01-02-01.wav\n",
      "03-01-02-02-02-02-01.wav\n",
      "03-01-02-01-02-02-01.wav\n"
     ]
    }
   ],
   "source": [
    "y_test_map = np.array(y_tes).T\n",
    "y_test = y_test_map[0]\n",
    "test_filename = y_test_map[1]\n",
    "y_train_map = np.array(y_trai).T\n",
    "y_train = y_train_map[0]\n",
    "train_filename = y_train_map[1]\n",
    "print(np.shape(y_train),np.shape(y_test))\n",
    "print(*test_filename,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-3.94841520e+02,  9.09605164e+01, -1.03667925e+01,  2.83785660e+01,\n",
      "       -5.13291034e+00, -7.90893363e+00, -1.60141624e+01, -2.62665932e+01,\n",
      "       -1.34115166e+01, -5.29609762e+00, -8.57799124e+00,  6.22029416e+00,\n",
      "       -1.89102808e+01,  7.52303020e+00, -6.88778960e+00, -9.86481646e+00,\n",
      "       -5.35330493e+00, -2.00894497e+00, -1.37563728e+01, -4.42616426e-01,\n",
      "       -8.71958602e+00, -7.72621132e+00, -2.85401424e+00, -4.49695138e+00,\n",
      "       -5.69129541e+00, -2.46792334e+00, -8.91658330e+00,  6.28479994e-01,\n",
      "       -8.33700524e+00, -2.08200559e+00, -6.63993147e+00, -4.90928375e+00,\n",
      "       -4.59367178e+00,  1.28458843e+00, -4.43022508e+00,  2.37076289e+00,\n",
      "       -1.79906297e+00,  4.94486915e+00,  2.42389144e+00,  2.63770450e+00,\n",
      "        6.24972950e-01,  6.62534216e-01,  5.90074892e-01,  5.88488630e-01,\n",
      "        6.10359921e-01,  6.03769624e-01,  4.90683505e-01,  5.13769120e-01,\n",
      "        5.39709270e-01,  5.30631902e-01,  5.20037695e-01,  5.27765536e-01,\n",
      "        8.16207094e-04,  5.77533199e-04,  2.44115450e-04,  3.69039753e-03,\n",
      "        1.54452725e-01,  4.76898366e-01,  5.67355336e-01,  1.75399276e-01,\n",
      "        1.39734403e-02,  2.87865540e-02,  3.01785063e-01,  2.94129023e-01,\n",
      "        1.32085469e-01,  1.60819704e-01,  1.95950077e-01,  1.00287788e-01,\n",
      "        3.40099554e-01,  2.28524469e-01,  1.02388329e-01,  8.17196886e-02,\n",
      "        1.49783844e-01,  5.73228693e-01,  7.13623553e-01,  2.02449070e-01,\n",
      "        2.81914153e-02,  5.20465122e-02,  9.38130260e-02,  3.18553056e-01,\n",
      "        4.93691268e-01,  2.73087124e-01,  1.09970296e-02,  3.62124911e-03,\n",
      "        6.87985891e-03,  1.47894758e-02,  1.13402319e-02,  4.05173384e-03,\n",
      "        6.91837491e-03,  2.43387551e-03,  3.76655179e-03,  5.67836981e-03,\n",
      "        1.87770121e-02,  4.24166678e-02,  2.71978765e-02,  2.41341870e-02,\n",
      "        2.19400526e-02,  1.79295908e-02,  2.15436344e-02,  3.73351259e-02,\n",
      "        3.94276027e-02,  2.22241772e-02,  7.55917319e-03,  4.98979435e-03,\n",
      "        8.05230549e-03,  2.82150910e-02,  3.62352736e-02,  6.03957014e-03,\n",
      "        4.75743527e-03,  8.28142682e-03,  1.27968051e-02,  5.53973303e-03,\n",
      "        2.04785748e-03,  4.89184599e-03,  6.32916759e-03,  2.81747702e-03,\n",
      "        1.70595213e-03,  1.41319064e-03,  2.01025092e-03,  2.11774168e-03,\n",
      "        1.79271866e-03,  1.32347999e-03,  1.01173131e-03,  8.89217544e-04,\n",
      "        9.89446219e-04,  1.67165635e-03,  1.89126413e-03,  3.96497662e-03,\n",
      "        2.78154688e-03,  3.78911194e-03,  7.88997659e-03,  2.89920381e-03,\n",
      "        3.93859587e-03,  2.22940857e-03,  1.16792236e-03,  4.22936221e-04,\n",
      "        5.70055652e-04,  2.95449042e-04,  4.12936265e-04,  3.06585699e-04,\n",
      "        5.07544334e-04,  6.21631371e-04,  7.63335176e-04,  2.42367619e-03,\n",
      "        2.59401704e-03,  5.88027940e-03,  5.02661378e-03,  4.05511090e-03,\n",
      "        1.58139323e-03,  7.27083715e-04,  2.56550930e-04,  1.55123920e-04,\n",
      "        1.47778700e-04,  1.86764515e-04,  2.72365671e-04,  1.38864722e-04,\n",
      "        2.29974061e-04,  3.62755847e-04,  5.33574158e-04,  8.68281030e-04,\n",
      "        5.74133996e-04,  2.73790985e-04,  2.22421388e-04,  1.43807731e-04,\n",
      "        1.09065996e-04,  1.41686079e-04,  2.52374140e-04,  3.99951139e-04,\n",
      "        2.11219155e-04,  1.87600880e-04,  1.91936050e-04,  1.16961790e-04,\n",
      "        7.46596055e-05,  5.28583016e-05,  3.58416324e-05,  3.65998708e-05,\n",
      "        3.34617870e-05,  2.91360801e-05,  7.99171923e-06,  5.36230011e-07]), array([-5.20614032e+02,  1.17171435e+02,  4.16630366e-01,  2.85198284e+01,\n",
      "        2.50716649e+00, -4.52208094e+00, -1.45837436e+01, -1.10599622e+01,\n",
      "       -1.94338273e+01,  3.34291682e+00, -5.03476332e+00, -7.72883558e-03,\n",
      "       -1.18805457e+01,  3.51795258e+00, -6.57253299e+00, -4.63751823e+00,\n",
      "       -7.56214513e+00,  5.68198899e+00, -1.73782872e+01,  4.38606758e-01,\n",
      "       -7.31209456e+00, -8.76733284e+00, -3.45458513e+00, -4.53006633e+00,\n",
      "       -4.38294370e+00, -8.44064797e-01, -6.56697987e+00, -1.38241016e+00,\n",
      "       -1.13360762e+01, -3.09792942e+00, -9.72323304e+00, -5.55006860e+00,\n",
      "       -2.79929210e+00, -5.13320773e+00, -9.84366035e+00, -8.61804580e+00,\n",
      "       -7.55751977e+00, -3.44431130e+00, -6.61034079e+00, -2.76146638e+00,\n",
      "        5.20173267e-01,  6.50723490e-01,  6.54240868e-01,  5.86582474e-01,\n",
      "        6.09583240e-01,  6.14973842e-01,  6.50201564e-01,  7.06774458e-01,\n",
      "        6.11683826e-01,  5.55223186e-01,  6.14773848e-01,  5.45625045e-01,\n",
      "        4.84070929e-06,  7.47916381e-05,  5.80098116e-03,  6.79196620e-02,\n",
      "        5.30040648e-02,  4.08543483e-03,  1.30501311e-03,  1.10836947e-02,\n",
      "        2.37408220e-02,  3.81293558e-02,  6.36652723e-03,  9.60750183e-03,\n",
      "        9.73133747e-03,  1.28871128e-02,  2.73765500e-02,  5.84182673e-03,\n",
      "        1.00394360e-02,  4.83760067e-03,  6.31441427e-03,  2.18122770e-02,\n",
      "        1.59613631e-02,  5.36011310e-03,  4.60802798e-03,  6.67721576e-03,\n",
      "        4.93324861e-03,  1.50999106e-03,  1.93167627e-03,  6.20573306e-03,\n",
      "        6.22840691e-03,  1.43875041e-03,  9.32433040e-04,  2.85312597e-03,\n",
      "        2.18836285e-03,  7.16037400e-04,  3.84838638e-04,  1.82270766e-04,\n",
      "        3.30937997e-04,  3.25325459e-04,  3.81766106e-04,  3.19853804e-04,\n",
      "        5.49755447e-04,  1.11990891e-03,  7.76586450e-04,  2.64062775e-04,\n",
      "        3.69833789e-04,  6.84766498e-04,  1.70959978e-03,  1.41261635e-03,\n",
      "        1.05131370e-03,  4.09987105e-04,  3.40635826e-04,  3.37176368e-04,\n",
      "        1.88016630e-04,  4.88118630e-04,  4.94842858e-04,  2.52140270e-04,\n",
      "        2.30953233e-04,  4.76500841e-04,  2.69315867e-04,  1.38011204e-04,\n",
      "        3.29349780e-04,  3.40558420e-04,  2.07476948e-04,  4.34616383e-04,\n",
      "        3.94432152e-04,  4.27199257e-04,  6.81057919e-05,  5.38290080e-04,\n",
      "        2.54735281e-04,  7.31026076e-05,  8.32945487e-05,  4.45375535e-05,\n",
      "        1.25273980e-04,  9.84228359e-05,  1.00036539e-04,  1.19337898e-04,\n",
      "        1.90536654e-04,  2.77145796e-04,  2.94142585e-04,  3.87070249e-04,\n",
      "        1.25818524e-04,  8.18873484e-05,  6.61298565e-05,  6.13258197e-05,\n",
      "        7.30932115e-05,  5.02237162e-05,  1.68125033e-05,  2.91775689e-05,\n",
      "        3.51887330e-05,  3.19025063e-05,  3.76116971e-05,  5.08194069e-05,\n",
      "        8.06706982e-05,  1.26791430e-04,  8.80085430e-05,  5.18925191e-05,\n",
      "        1.83298536e-05,  1.04611434e-05,  5.44067430e-06,  5.88104368e-06,\n",
      "        5.19153786e-06,  1.27354102e-05,  1.81312330e-05,  3.46720305e-05,\n",
      "        5.21726750e-05,  7.76155716e-05,  7.68624624e-05,  7.03189030e-05,\n",
      "        4.20386789e-05,  2.25065956e-05,  4.36532015e-05,  1.94607362e-05,\n",
      "        3.62338432e-05,  3.67195007e-05,  3.58285157e-05,  1.61553961e-05,\n",
      "        1.89819619e-05,  2.17770292e-05,  1.11950511e-05,  6.27339844e-06,\n",
      "        5.26104286e-06,  6.22397294e-06,  6.56201985e-06,  6.95130755e-06,\n",
      "        7.77619920e-06,  3.93839508e-06,  1.13687408e-06,  5.87192719e-08]))\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "# print((x_train.shape[0], x_test.shape[0]))\n",
    "print((x_train[0], x_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of features extracted\n",
    "# print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:351: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.20614032e+02  1.17171435e+02  4.16630366e-01 ...  3.93839508e-06\n",
      "   1.13687408e-06  5.87192719e-08]\n",
      " [-4.05837321e+02  8.57629892e+01 -1.27275260e+01 ...  1.82571301e-04\n",
      "   4.11067921e-05  2.69036907e-06]\n",
      " [-4.23196873e+02  1.02849796e+02 -1.55268126e+01 ...  2.23983010e-05\n",
      "   4.63932713e-06  2.28639453e-07]\n",
      " ...\n",
      " [-5.14689397e+02  1.06890684e+02 -2.00363480e+00 ...  1.59950670e-05\n",
      "   2.75984489e-06  1.24071011e-07]\n",
      " [-4.85500973e+02  9.69459957e+01 -1.78040310e+00 ...  4.53421642e-05\n",
      "   8.13862794e-06  3.69782932e-07]\n",
      " [-4.61759397e+02  1.17045060e+02 -9.08470311e+00 ...  3.65003157e-05\n",
      "   4.64132073e-06  2.53890407e-07]]\n"
     ]
    }
   ],
   "source": [
    "#Predict for the test set\n",
    "print(x_test)\n",
    "# y_pred=model.predict(x_test)\n",
    "# y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4 0 0]\n",
      " [0 1 0]\n",
      " [0 0 3]]\n",
      "Accuracy Score : 1.0\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       1.00      1.00      1.00         4\n",
      "     fearful       1.00      1.00      1.00         1\n",
      "       happy       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LAST Visualisation (Summarisation)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix')\n",
    "print(results) \n",
    "print ('Accuracy Score :',accuracy_score(y_test, y_pred) )\n",
    "print('Report')\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The problem is here . After Prediction I only get the predicted results where as i also want that predicted \n",
    "# output should match their label and corresponding filename for the particular prediction should\n",
    "#also be printed in .csv file ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictions                file_names\n",
      "0        calm  03-01-02-02-01-01-01.wav\n",
      "1     fearful  03-01-06-01-02-02-01.wav\n",
      "2       happy  03-01-03-01-01-02-01.wav\n",
      "3       happy  03-01-03-02-01-02-01.wav\n",
      "4       happy  03-01-03-01-02-02-01.wav\n",
      "5        calm  03-01-02-02-01-02-01.wav\n",
      "6        calm  03-01-02-02-02-02-01.wav\n",
      "7        calm  03-01-02-01-02-02-01.wav\n"
     ]
    }
   ],
   "source": [
    "#Store the Prediction probabilities into CSV file \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "y_pred1 = pd.DataFrame(y_pred, columns=['predictions'])\n",
    "y_pred1['file_names'] = test_filename\n",
    "print(y_pred1)\n",
    "y_pred1.to_csv('predictionfinal.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['calm' '03-01-02-02-01-01-01.wav']\n",
      " ['fearful' '03-01-06-01-02-02-01.wav']\n",
      " ['happy' '03-01-03-01-01-02-01.wav']\n",
      " ['happy' '03-01-03-02-01-02-01.wav']\n",
      " ['happy' '03-01-03-01-02-02-01.wav']\n",
      " ['calm' '03-01-02-02-01-02-01.wav']\n",
      " ['calm' '03-01-02-02-02-02-01.wav']\n",
      " ['calm' '03-01-02-01-02-02-01.wav']]\n"
     ]
    }
   ],
   "source": [
    "# For verification type\n",
    "print(y_test_map.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
